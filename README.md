# LangChain 학습하기

---

## RAG

### 설명

- Retrieval Augmented Generation
- 검색 증강 생성
  > 대규모 언어 모델의 출력을 최적화하여 응답을 생성하기 전에 학습 데이터 소스 외부의 신뢰할 수 있는 지식 베이스를 참조하도록 하는 프로세스입니다. 대규모 언어 모델(LLM)은 방대한 양의 데이터를 기반으로 학습되며 수십억 개의 매개 변수를 사용하여 질문에 대한 답변, 언어 번역, 문장 완성과 같은 작업에 대한 독창적인 결과를 생성합니다. RAG는 이미 강력한 LLM의 기능을 특정 도메인이나 조직의 내부 지식 기반으로 확장하므로 모델을 다시 교육할 필요가 없습니다. 이는 LLM 결과를 개선하여 다양한 상황에서 관련성, 정확성 및 유용성을 유지하기 위한 비용 효율적인 접근 방식입니다. - aws 설명 중

### 흐름
  <img src="https://github.com/jiyongYoon/study_langchain/assets/98104603/0838d544-feec-40f5-a2f2-f917e17adb4e" width="80%">

  1. 사용자 질문
  2. 질문을 이용해 저장소에 검색
  3. 지시 프롬프트 + 질문 + 검색 결과 n개 -> 언어모델(ex, gpt)에게 제공
  4. 언어 모델이 답변 생성
  5. 답변 출력

### 구성 요소

1. 문서 또는 데이터 가공
   - 현존하는 대부분의 문서 양식 또는 데이터 사용 가능
   - 문서 또는 데이터는 반드시 나누어야 함
     - 모델 별 토큰 크기의 제한
     - 결과물의 질을 높이기 위함
     - 내용의 주제 기준으로 나누는 것이 범용성이 좋을 수 있음
       - 문서의 성격에 따라 나누는 기준이 달라져야 할 수 있음
2. 임베딩 모델
   - 글자, 단어, 문장을 분류하는 작업
     - 해당 단어를 수치화 하게 됨
     - 임베딩 모델은 지정된 차원 수를 가지고 있음
       - 오픈AI의 임베딩 모델인 Ada 모델(모델명: text-embedding-ada-002)는 1536차원을 지원함
       - 때문에 임베딩 모델을 중간에 변경하면 기존 데이터와 호환할 수 없음 (다시 해당 모델로 임베딩 해야함)
3. 언어 모델
4. 벡터 데이터 베이스
   - 임베딩된 수치화 데이터를 저장하는 저장소
5. 프롬프트


### 참고자료
- [랭체인LangChain 노트](https://wikidocs.net/233341)
- [모두의AI 유튜브](https://www.youtube.com/@AI-km1yn)
- [GPTers 커뮤니티 유튜브](https://youtu.be/m7cNjCVpSrw?si=YYCMSQjdPyXvfFIL)