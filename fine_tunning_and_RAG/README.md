# 파인튜닝과 RAG

---

어떠한 문서를 기반으로 질문에 대한 답변을 해주는 기능을 개발중에 있다. 학습 및 데모 기능들을 개발하다보니, 두 가지 방법을 알게 되었다.

- 파인튜닝을 통한 LLM을 제공
- 문서 기반으로 검색증강생성(RAG) 구현

학습 결과, 두 가지는 장단점이 있었고 지금까지 공부했던 RAG가 현재 수준에서는 더 적합하다고 판단을 내렸다.

---

## 파인튜닝

파인 튜닝이란, 사전 학습 모델에 도메인에 특화된 데이터를 추가로 학습시켜 해당 도메인에 특화된 LLM을 생성하는 작업이다. 우리가 흔히 아는 chatGPT, claude, gemini 등은 범용 모델이라 많은 데이터를 학습했지만, 도메인에 '특화'되어있지는 않다.

### 장점

- 일관된 답변: 언어 스타일이나 답변 형식을 고정시키고 유지하기 용이하다.
- 고정된 정보: 학습을 위해 한 번 파인튜닝을 하면 안정적인 정보로 사용할 수 있다.
- 빠른 응답: 외부 검색 과정 없이 학습된 내용에서 모델이 답변만 바로 생성하므로 응답 속도가 빠르다.

### 단점

- 업데이트 필요: 파인튜닝 시 제공한 데이터까지만 반영하므로, LLM만을 사용하기 위해서는 다시 파인튜닝을 해야한다.
- 자원 소모: 파인튜닝 과정에서 자원(데이터셋의 생성 및 품질 검토, 학습을 위한 시간 및 자원)이 많이 소모된다.
- 할루시네이션 가능성 내포

## RAG

RAG란, 사전 훈련된 언어 모델의 외부에서 데이터를 가져와 임베딩하여 Vector DB에 저장하고, 질문에 대해 모델이 직접 답변을 생성하는 대신 관련 문서를 Vector DB에서 검색한 후 그 내용을 기반으로 답변을 생성하는 방법이다.

### 장점

- 정보 업데이트 가능: 계속해서 추가적인 답변 근거(자료)를 제공할 수 있다.
- 근거 있는 답변 생성: 임베딩 된 데이터 기반으로 답변을 하기 때문에 LLM의 고질적인 할루시네이션 문제에서 위험도가 덜하다.
- 사전 비용 낮음: 파인 튜닝에 비해 사전 학습된 언어 모델만을 필요로 하기 때문에 LLM을 서빙하는데 필요한 비용은 낮은 편이다.

### 단점

- 느린 응답: 외부 검색 과정이 필요하기 때문에 Context 및 데이터가 방대할수록 응답이 느릴 수 밖에 없는 구조다.
- 시스템 복잡성 증가: 이런 일련의 과정을 컨트롤해야하기 때문에 파인튜닝된 LLM 모델만 단독으로 사용하는 것에 비해 개발 및 유지보수의 비용이 높다.

## [어떤 기준으로 선택해야 하는가?](https://towardsdatascience.com/rag-vs-finetuning-which-is-the-best-tool-to-boost-your-llm-application-94654b1eaba7)

위의 극명한 장단점들로 인해, 서비스에서 필요로하는 것에 따라 선택지가 나누어지게 되는 것 같다.

### 외부 데이터의 업데이트가 자주 필요한가 -> RAG

신규 데이터가 생겼을 때 RAG의 Vector DB를 갱신하는 일이 모델을 추가학습하는 것보다 간편하다.

### 추가적인 외부 데이터의 동적 접근이 필요한가 -> RAG

추가적으로 임베딩하여 동적으로 자료를 넣어주도록 구성하기가 상대적으로 쉽다.

### 베이스 모델의 행동, 스타일, 도메인 특화 지식 등을 유지해야 하는가 -> Fine-tunning

항상 비슷한 톤과 답변 스타일, 일관된 답변이 필요한 경우 파인튜닝을 통해 학습을 시키는 방법이 더 좋다.

### 할루시네이션 억제가 중요한가? 답변에 대한 과정을 우리가 반드시 모니터링 할 수 있어야 한다? -> RAG 

일반적으로 LLM 답변을 생성하는 과정은 블랙박스와 같다. RAG는 자료에서 답변을 만들어내므로 할루시네이션 억제가 잘 된다. 또 어떤 순서와 근거로 답변이 생성되었는지를 모니터링 할 수 있다.

---

참고자료: 
1. [Skelter Labs 블로그](https://www.skelterlabs.com/blog/rag-vs-finetuning)
2. [marcus-story 블로그](https://marcus-story.tistory.com/29)

